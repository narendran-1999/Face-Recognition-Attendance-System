{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nMHMcJQuAPOp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681926775838,"user_tz":-330,"elapsed":10479,"user":{"displayName":"21MX114 - NARENDRAN T R","userId":"05953325443593361031"}},"outputId":"67178b27-6d3c-4faa-a70b-bf3bd3b568e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imutils in /usr/local/lib/python3.9/dist-packages (0.5.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-facenet\n","  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mtcnn\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from mtcnn->keras-facenet) (2.12.0)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.9/dist-packages (from mtcnn->keras-facenet) (4.7.0.72)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from opencv-python>=4.1.0->mtcnn->keras-facenet) (1.22.4)\n","Building wheels for collected packages: keras-facenet\n","  Building wheel for keras-facenet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10385 sha256=bb7e7f0cd32c300e56664fb909cc96236444f07681ad526ea3786ee40b68edcb\n","  Stored in directory: /root/.cache/pip/wheels/73/5d/41/90b5d28ca667cfc4748ae859fa4f0b85b936d73207a073ded5\n","Successfully built keras-facenet\n","Installing collected packages: mtcnn, keras-facenet\n","Successfully installed keras-facenet-0.3.2 mtcnn-0.1.1\n"]}],"source":["!pip install imutils\n","!pip install keras-facenet"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from imutils.video import FileVideoStream"],"metadata":{"id":"ePbaE0q-yRj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoEw5XHNcgk5","executionInfo":{"status":"ok","timestamp":1681926799087,"user_tz":-330,"elapsed":17540,"user":{"displayName":"21MX114 - NARENDRAN T R","userId":"05953325443593361031"}},"outputId":"a4ce41ca-df89-4e5e-fdd7-b02117c55068"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w1Nu6wXWDDp3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681926804766,"user_tz":-330,"elapsed":1745,"user":{"displayName":"21MX114 - NARENDRAN T R","userId":"05953325443593361031"}},"outputId":"07d33d26-8182-441c-e7c5-d83dbafba3da"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-04-19 17:53:21--  https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28104 (27K) [text/plain]\n","Saving to: ‘deploy.prototxt’\n","\n","\rdeploy.prototxt       0%[                    ]       0  --.-KB/s               \rdeploy.prototxt     100%[===================>]  27.45K  --.-KB/s    in 0.002s  \n","\n","2023-04-19 17:53:21 (12.0 MB/s) - ‘deploy.prototxt’ saved [28104/28104]\n","\n","--2023-04-19 17:53:21--  https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel [following]\n","--2023-04-19 17:53:21--  https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10666211 (10M) [application/octet-stream]\n","Saving to: ‘res10_300x300_ssd_iter_140000.caffemodel’\n","\n","res10_300x300_ssd_i 100%[===================>]  10.17M  --.-KB/s    in 0.1s    \n","\n","2023-04-19 17:53:22 (106 MB/s) - ‘res10_300x300_ssd_iter_140000.caffemodel’ saved [10666211/10666211]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n","!wget https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"]},{"cell_type":"code","source":["INFILE = \"/content/drive/MyDrive/FR_Colab/hh.mp4\"\n","OUTFILE = \"/content/drive/MyDrive/FR_Colab/hh_processed.mp4\"\n","DATASET_DIR = \"/content/drive/MyDrive/FR_Colab/face_dataset\"\n","MODEL = \"/content/drive/MyDrive/FR_Colab/built_model.h5\""],"metadata":{"id":"h9cS5OEamggM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import datetime\n","from IPython.display import clear_output\n","\n","# Load the face detection model\n","model_file = 'deploy.prototxt'\n","model_weights = 'res10_300x300_ssd_iter_140000.caffemodel'\n","net = cv2.dnn.readNetFromCaffe(model_file, model_weights)\n","\n","# Start the video stream\n","vs = FileVideoStream(INFILE).start()\n","\n","# Get the total number of frames in the video\n","total_frames = int(vs.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","# Get the video writer ready\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","fps = vs.stream.get(cv2.CAP_PROP_FPS)\n","width = int(vs.stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(vs.stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","out = cv2.VideoWriter(OUTFILE, fourcc, fps, (width, height))# --OUTPUT VIDEO PATH!!!\n","\n","# Loop through the frames in the video stream\n","while True:\n","    # Read the next frame from the video stream\n","    frame = vs.read()\n","\n","    # If there are no more frames, break out of the loop\n","    if frame is None:\n","        break\n","\n","    (h, w) = frame.shape[:2]\n","    blob = cv2.dnn.blobFromImage(frame, 0.5, (h,h), (104.0, 177.0, 123.0))\n","\n","    net.setInput(blob)\n","    detections = net.forward()\n","\n","    for i in range(0, detections.shape[2]):\n","\n","        confidence = detections[0, 0, i, 2]\n","\n","        if confidence < 0.6:\n","            continue\n","\n","        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n","        (startX, startY, endX, endY) = box.astype(\"int\")\n","\n","\n","        #UNCOMMENT THIS PART FOR DATASET COLLECTION----------------------------------------------------------\n","        #img = frame[startY:endY,startX:endX]\n","        #try:\n","        #    cv2.imwrite(\"/content/drive/MyDrive/face_dataset/\"+str(datetime.datetime.now())+\".jpg\",img)\n","        #except:\n","        #    print(\"imwrite error\")\n","\n","\n","        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n","\n","\n","    # Write the frame with bounding boxes to the output video file\n","    out.write(frame)\n","\n","    clear_output(wait=True)\n","    frame_num = int(vs.stream.get(cv2.CAP_PROP_POS_FRAMES))\n","    # Calculate the progress percentage\n","    progress_pct = int((frame_num / total_frames) * 100)\n","    # Print the progress in the console\n","    print(f'Frame {frame_num} /{total_frames} ({progress_pct}% complete)')\n","\n","    # Wait for a key event\n","    key = cv2.waitKey(1) & 0xFF\n","\n","    # If the 'q' key is pressed, break out of the loop\n","    if key == ord('q'):\n","        break\n","\n","# Release the video stream and video writer\n","vs.stop()\n","out.release()\n","\n","# Destroy all windows\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nS5QFJ-ozHr","executionInfo":{"status":"ok","timestamp":1681928225660,"user_tz":-330,"elapsed":1409297,"user":{"displayName":"21MX114 - NARENDRAN T R","userId":"05953325443593361031"}},"outputId":"214680b3-3fe6-4708-da5a-00709feeaa22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Frame 0 /5856 (0% complete)\n"]}]},{"cell_type":"code","source":["#RUN FOR FACE RECOGNITION PREP-----------------------------------------------------------------------------------------\n","import tensorflow as tf\n","from keras_facenet import FaceNet\n","from keras.models import load_model\n","import csv\n","import os\n","import datetime\n","from IPython.display import clear_output\n","\n","# Set the directory path\n","directory_path = DATASET_DIR\n","\n","# Get the list of all folders in the directory\n","label = [folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n","print(label)\n","\n","facenet_model = FaceNet()\n","fmodel = load_model(MODEL)\n","\n","def recFace(image):\n","\n","    #lbl = \"\"\n","    max = -1\n","\n","    if np.any(image):\n","\n","        try:\n","\n","            global facenet_model, fmodel\n","\n","            image = cv2.resize(image,(224,224))\n","            image = tf.keras.preprocessing.image.img_to_array(image)\n","\n","            image = tf.constant(image)\n","            image = tf.keras.backend.cast(image, 'float32')\n","            image = tf.keras.backend.reshape(image, (1, 224, 224, 3))\n","            image = tf.keras.backend.concatenate([image, image], axis=0)\n","\n","            imgs = [image]\n","\n","            embeddings = facenet_model.embeddings(imgs)\n","\n","            embeddings = tf.constant(embeddings)\n","            embeddings = tf.keras.backend.cast(embeddings, 'float32')\n","\n","            pred = fmodel.predict(embeddings)\n","            max = np.argmax(pred[0])\n","\n","            print(pred)\n","\n","            if pred[0][max] < 0.6:\n","                #lbl = \"Unknown\"\n","                max = -1\n","\n","        except:\n","            print('frame error')\n","\n","    return max#, lbl"],"metadata":{"id":"tBUcQmrR4CnY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681068608564,"user_tz":-330,"elapsed":4506,"user":{"displayName":"21MX114 - NARENDRAN T R","userId":"05953325443593361031"}},"outputId":"cccac45a-98d9-497c-d07a-115f54fd7eab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['bodyguard', 'man1', 'man2', 'masked guard', 'old lady', 'man3', 'roshan', 'blackbeard man', 'target', 'basim', 'boy', 'greybeard man', 'man5', 'helmet guard', 'fakir', 'dark lady', 'unfortunate vendor', 'man4', 'wmn1', 'beard-only man', 'dark man', 'young lady', 'unmasked guard']\n"]}]},{"cell_type":"code","source":["#RUN FOR FACE RECOGNITION-----------------------------------------------------------------------------------------\n","\n","# Load the face detection model\n","model_file = 'deploy.prototxt'\n","model_weights = 'res10_300x300_ssd_iter_140000.caffemodel'\n","net = cv2.dnn.readNetFromCaffe(model_file, model_weights)\n","\n","# Start the video stream\n","vs = FileVideoStream(INFILE).start()\n","\n","# Get the total number of frames in the video\n","total_frames = int(vs.stream.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","# Get the video writer ready\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","fps = vs.stream.get(cv2.CAP_PROP_FPS)\n","width = int(vs.stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(vs.stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","out = cv2.VideoWriter(OUTFILE, fourcc, fps, (width, height))\n","\n","# Loop through the frames in the video stream\n","while True:\n","    # Read the next frame from the video stream\n","    frame = vs.read()\n","\n","    # If there are no more frames, break out of the loop\n","    if frame is None:\n","        break\n","\n","    (h, w) = frame.shape[:2]\n","    blob = cv2.dnn.blobFromImage(frame, 0.5, (h,h), (104.0, 177.0, 123.0))\n","\n","    net.setInput(blob)\n","    detections = net.forward()\n","\n","    for i in range(0, detections.shape[2]):\n","\n","        confidence = detections[0, 0, i, 2]\n","\n","        if confidence < 0.6:\n","            continue\n","\n","        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n","        (startX, startY, endX, endY) = box.astype(\"int\")\n","\n","        \n","        img = frame[startY:endY,startX:endX]\n","        face_id = recFace(img)\n","        if face_id != -1:\n","            face = label[face_id][0]\n","        else:\n","            face = \"Unknown\"\n","        cv2.putText(frame,face,(startX-10,startY-5),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2,cv2.LINE_AA)\n","\n","\n","        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n","\n","    # Write the frame with bounding boxes to the output video file\n","    out.write(frame)\n","\n","    clear_output(wait=True)\n","    frame_num = int(vs.stream.get(cv2.CAP_PROP_POS_FRAMES))\n","    # Calculate the progress percentage\n","    progress_pct = int((frame_num / total_frames) * 100)\n","    # Print the progress in the console\n","    print(f'Frame {frame_num} /{total_frames} ({progress_pct}% complete)')\n","\n","    # Wait for a key event\n","    key = cv2.waitKey(1) & 0xFF\n","\n","    # If the 'q' key is pressed, break out of the loop\n","    if key == ord('q'):\n","        break\n","\n","# Release the video stream and video writer\n","vs.stop()\n","out.release()\n","\n","# Destroy all windows\n","cv2.destroyAllWindows()"],"metadata":{"id":"99svzCVuopNd"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1rc9QVD-OTI7-sfNFlfo8UBcUj15wwEJb","authorship_tag":"ABX9TyO+SUchZcDjpkYgdziWjrz4"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}